{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Mastering PyTorch Hooks\n",
                "\n",
                "Hooks are a powerful feature in PyTorch that allow you to inspect or modify the behavior of a model during the forward or backward pass. They are essential for tasks like:\n",
                "- **Feature Visualization** (e.g., Grad-CAM)\n",
                "- **Debugging** (checking gradients for NaNs)\n",
                "- **Modifying Gradients** (clipping, scaling)\n",
                "\n",
                "There are two main types of hooks:\n",
                "1. **Forward Hooks**: Triggered during the forward pass.\n",
                "2. **Backward Hooks**: Triggered during the backward pass."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.nn.functional as F\n",
                "\n",
                "# Let's define a simple CNN model\n",
                "class SimpleNet(nn.Module):\n",
                "    def __init__(self):\n",
                "        super().__init__()\n",
                "        self.conv1 = nn.Conv2d(1, 10, kernel_size=3)\n",
                "        self.conv2 = nn.Conv2d(10, 20, kernel_size=3)\n",
                "        self.fc = nn.Linear(320, 10)\n",
                "\n",
                "    def forward(self, x):\n",
                "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
                "        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
                "        x = x.view(-1, 320)\n",
                "        x = self.fc(x)\n",
                "        return x\n",
                "\n",
                "model = SimpleNet()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Forward Hooks\n",
                "\n",
                "A forward hook has the signature `hook(module, input, output)`. It allows you to access the input and output of a layer."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define a forward hook\n",
                "activation = {}\n",
                "def get_activation(name):\n",
                "    def hook(model, input, output):\n",
                "        activation[name] = output.detach()\n",
                "    return hook\n",
                "\n",
                "# Register the hook on the second conv layer\n",
                "# This is often used in Grad-CAM to get the feature maps\n",
                "handle_fwd = model.conv2.register_forward_hook(get_activation('conv2'))\n",
                "\n",
                "# Let's run a forward pass\n",
                "dummy_input = torch.randn(1, 1, 28, 28)\n",
                "output = model(dummy_input)\n",
                "\n",
                "print(f\"Captured activation shape: {activation['conv2'].shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Backward Hooks\n",
                "\n",
                "A backward hook has the signature `hook(module, grad_input, grad_output)`. It allows you to inspect or modify gradients."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "gradients = {}\n",
                "def get_gradients(name):\n",
                "    def hook(model, grad_input, grad_output):\n",
                "        gradients[name] = grad_output[0].detach()\n",
                "        print(f\"Gradients for {name} captured!\")\n",
                "    return hook\n",
                "\n",
                "# Register backward hook\n",
                "# Note: register_full_backward_hook is generally preferred over register_backward_hook\n",
                "handle_bwd = model.conv2.register_full_backward_hook(get_gradients('conv2'))\n",
                "\n",
                "# Backward pass\n",
                "loss = output.sum()\n",
                "loss.backward()\n",
                "\n",
                "print(f\"Captured gradient shape: {gradients['conv2'].shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Removing Hooks\n",
                "\n",
                "It is important to remove hooks when you are done, otherwise they will accumulate and slow down your model or cause memory leaks."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Remove the hooks using the handles we stored earlier\n",
                "handle_fwd.remove()\n",
                "handle_bwd.remove()\n",
                "print(\"Hooks removed!\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}